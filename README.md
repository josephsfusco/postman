# Overview
The purpose of this project is to create a simple HTTP Server which which has two services
* Authentication Service

* Business Service 

The two servcies are "seperate" and work in independently to authenticate a user logging in with basic credentials, provide them with a bearer token for their session, and subsequently allow them access to the business server for the remaineder of their session. 

Basic auth is maintained by a simple in memory database with usernames (emails) and passwords encrypted using a simple hash. 

Tokens are generated by Auth Server when a users logs in with proof of basic credentials. The token is created, stored in memeory along with a TTL of thiery (30) second.

>Note to reviewers: thirty seconds is extremely low and is configured as such for demo purposes. 

The Client will then include the token as a header in all subsequent requests to the Business service verifing authenticity of the user for the session. 
To requests data Client must include the Bearer Token in the request headers, to verify authenticity Business Service then makes a follow-up outbound request to Auth Service to validate the token. This ensures a seperation of duty and allowed Business Service the liberty to have no knowledge of what keys are valid or not.


# Getting Started
**Running Remotely**

This project is deployed on Heroku at the following domain {domain} 

> Note to reviewers: The server may be asleep and take a few moments to wake up for the first request. 

**Running Locally**

Docker up the docker compose file and run the following commands. ensure that you are in the `/postman` directory
```
$ pwd
> /postman

$ ./startServer
> Serving Flask app 'server'
> Running on http://x.x.x.x:xxxx
```

**Using the App** 

1. Using the Postman App, start by requesting a bearer token. Make a [`POST`] request to `/login` using the below user name and password. Find the request format documented below in the `Endpoints` section
   
> `username: jsf.fusco@gmail.com`
>
> `password: postman`

2. Follow by requesting data. Make a [`GET`] request to `/data` include the bearer token generated in step (1) in the headers. Find the request format documented below in the `Endpoints` section

> Bonus: setting up a Postman Flow works very well for this. 


# Endpoints
### **Public**

  ``` 
  /login
     Body: { 'username' : <username>,
             'password' : <password>
     }
  
     Response: {'token' : <bearer token>}
  ```
  
  ```
  /data
      Headers: {'token' : <bearer token>}
      
      Response: {'data' : <data>}
  ```

### **Internal**
```
/validateToken
    Body: {'token' : <bearer token>}

    Response: {'authenticated' : <bool>}
```

# Authentication
### **Basic Authentication**
We use a simple in memeory data base which stores usernames and encrypted passwords. In order to maintain a basic level of security passwords are encrpyted using a very simple one way hash. When we, the server, rerecieve a login request we hash the value of the user provided password and verify it matches that of the hash in the database, crucially this means we never decrpt the known password. 

### **Bearer Token Authentication**
First, What is a bearer token? A Bearer Token is a simple token which provides the bearer of the token access to anything secured by the token. These tokens often come in a few different flavors, reinflating, fixed ttl, and single use. In practice for client to server communication reinflating tokens are the most common which is what we've decdied to do here. By comparison fixed ttl are frequently used for server to server communication and single use are used for account creation verification. 

Its important to note that bearer tokens are only secure over HTTPS and not HTTP as the packaged can be sniffed and the contents including the token can be compromised by an attacker. 

> **Note to reviewers:** For simplicity across local and remote deploys we are in fact using HTTP here but we would not if deploying to anything but a dev environment. 

Next, Lets dive into our implmentation of them. Upon providing sucessful proof of basic auth our application creates a token object initializing it with some basic infrmation; Time to Live (TTL), original creation moment, and refresh count. When Client makes a request to `/data` the token must be included in the headers. The Business Server begins by making an internal call out to the Auth Server with the token requesting its authenticity. If valid the Auth Server reinflates the token giving it another thirty (30) to live and returns its authenticity status to the calling service, in this case Business Service. 


# Memory Management
A new token is created each time a user requests one using `/login` as the token is stored in memeory this being left unmanaged will cause memory bloat. It is therefore impatative that we have a medium of removing stale tokens from memory. 

we can considered two different approaches to handle this.

First, lets look at the source of the issue, `/login` is the sole culprate of creating and caching new tokens it is therefore obvious to leverage the invocation of this endpoint as a mechanism to trigger cleanup. The obvious drawback to this would be user experience. Imagine a user having to wait for a background cleanup job to finish just to log in. 

Second, lets look at an option that doesnt impact the user experience, `Background Cleanup` supose create a backgrounc clean up job which runs at scheduled intervals to manage dead tokens. 

While we can consider both options and at our current size we will perhaps see minimal difference with either solution, we may want to approach this problem with some foresight as to our our application may scale. As we grow managing tokens will turn into a larger data structure and performance problem, because of this we should decouple this from our....... It is for this reason that we pick the second approach. 

As we scale further we will want to look into outside services that may help us. Services like Redis have tools to help solve these problems so modularizing our code so a new service can plug and play into our existing architecture is paramount. 

As our application scales how  considered both options I decided to use the second approach as it seperates delegation of work and modularises the code base. This would make scaling the project much easier in the future. 

Services like Redis have ways of handling

# Flow
1) Client initiates by making call to Auth Server authenticating using the provided given username and password.
2) If basic creds are valid Auth Server generates a Bearer Token and responds with it to Client.
3) Client makes a subsequent call to Business Server including the Bearer Token in the request headers.
4) Business Server makes an internal call to Auth Server to verify the Token.
5) Auth Server returns the Authenticity of the Token and reinflates the token if valid
6) If valid Business Server responds with Data

![](/images/FlowChart.png)

# Logging

We've included a very basic logging framework. This could easily be extended to have log levels and implement a more extensive logging library. 

# Testing
### **Unit Testing**
Basic unit test coverage provdied. For a given function we are ensuring positive and negative test cases exist. 
```
$ pwd
> /postman

$ ./runTests
> testing output
```
> Note: We are not testing 100% for the purpose of this exercise but would ensure we have complete coverage for production level code.

### **End to End Testing**
State diagram shows all testing flows 

- [ ] All paths tested and succeded 
  
![](/images/StateDiagram.png)

# Future Improvements, Scalability & System Design Considerations
### Database and Memory Managment 
First lets quickly look at the users 'database' this would obviously not be stored in memeory as it is now, in my opinion the obvious choice would be a relational database to store user information and we would expand users into a class that could contain other attributes such as ID, email, etc. 

Since we've primaryly focused on building an authentication service. we should explore what scalability looks like for it. while the size of each token is very small, perhaps 100bytes as we scale memory is not our primary concern however we may want to explore leveraging an outside service for some of the other built in tools it may contain. Redis is a great example of a service which we could leverage, two functions straight out of the box which would help our system are Redis's cleanup functionality and token reinflation. 

There are services out there like Redis which would take some of work off of us to help out like handling reinfaltion and cleanup. 


### abstraction and 3rd party usability. 
the seperation of services allows for 



# TODO

- [X] fix cleanup job 
- [X] return 401s from public servides

- [X] check status codes on auth response 
- [X] finish function documentation
- [X] logging
- [X] unit testing   
- [X] finish overview documentation
- [x] finish getting started doc 
- [ ] move all strings to constants  
- [ ] finish cleanup 
- [ ] fix URL http/https issue (might not be an issue) 
- [ ] README future improvements and scalability